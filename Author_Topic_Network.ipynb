{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RehamJamal13/model/blob/main/Author_Topic_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdB7CGGwBs3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b5bc8f-a17b-4d60-998a-54ce2e207067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMpGYFGPIOSG"
      },
      "outputs": [],
      "source": [
        "#@title Download pakages\n",
        "#NATURAL LANGUAGE PROCESSING\n",
        "!pip install pandas\n",
        "!pip install networkx\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pjVBC7qzPV5G"
      },
      "outputs": [],
      "source": [
        "#@title Load Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "#from Topic_Modeling import *\n",
        "#import scispacy\n",
        "#import spacy\n",
        "#import en_core_sci_lg\n",
        "import networkx as nx\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "142_cGxoPE_G"
      },
      "outputs": [],
      "source": [
        "#@title Load Data\n",
        "df = pd.read_csv('/content/Copy of Bibliography_2016 - Sheet1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.loc[:,['Author','processed_title','TOPIC_ID','DOC_ID']]"
      ],
      "metadata": {
        "id": "eEnprcA3g-Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import itertools\n",
        "from pickle import NONE\n",
        "def Author_network():\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/Colab_Notebooks/Author_paper.csv\",'w') as f :\n",
        "        writer = csv.writer(f)\n",
        "        #df2.index = np.arange(1,len(df2)+1)\n",
        "        # field names\n",
        "        fields = ['DOC_ID','Author']\n",
        "        # writing the fields\n",
        "        writer.writerow(fields)\n",
        "        for index in df2.index:\n",
        "          df2['Author'] = df2['Author'].fillna(\"Unknown author\")\n",
        "          \"\"\"if df2.loc[index,'Author'] == NONE:\n",
        "          df2.loc[index,'Author'] = \"Unknown author\"\"\"\n",
        "          Authors = []\n",
        "          DocId = df2.loc[index,'DOC_ID']\n",
        "          Authors.append(df2.loc[index,'Author'].split(\",\"))\n",
        "          for author in Authors:\n",
        "            writer.writerows(zip(itertools.repeat(DocId),author))\n",
        "Author_network()\n"
      ],
      "metadata": {
        "id": "Bp-T1JuDovjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "+1#@title Author_edges\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/Author_paper.csv')\n",
        "df_authors = df3.explode('AUTHORS')\n",
        "df_authors.to_csv('/content/drive/MyDrive/Colab_Notebooks/Author_paper.csv')"
      ],
      "metadata": {
        "id": "4rpLcqv9EQmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create empty dictionary for coauthors\n",
        "coauthors = {}\n",
        "\n",
        "# Read in the CSV file\n",
        "with open('document_authors.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # skip header row\n",
        "    for row in reader:\n",
        "        document, author = row\n",
        "        if author not in coauthors:\n",
        "            coauthors[author] = set()\n",
        "        authors = set()\n",
        "        # Loop through CSV file to find all authors for current document\n",
        "        with open('document_authors.csv') as f2:\n",
        "            reader2 = csv.reader(f2)\n",
        "            next(reader2)  # skip header row\n",
        "            for row2 in reader2:\n",
        "                if row2[0] == document:\n",
        "                    authors.add(row2[1])\n",
        "        # Add coauthors for current author to dictionary\n",
        "        for coauthor in authors - {author}:\n",
        "            coauthors[author].add(coauthor)\n",
        "\n",
        "# Print the coauthors for each author\n",
        "for author, coauthor_set in coauthors.items():\n",
        "    coauthors_list = sorted(list(coauthor_set))\n",
        "    print(f'{author}: {\", \".join(coauthors_list)}')"
      ],
      "metadata": {
        "id": "5RMqw4NKdrRv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}